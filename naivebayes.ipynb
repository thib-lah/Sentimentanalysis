{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6f1316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\thiba\\anaconda3\\lib\\site-packages (1.12.1)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0,>=0.0.14 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (0.0.18)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (3.7.4.post0)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (5.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: pandas in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (2021.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (1.20.1)\n",
      "Requirement already satisfied: dill in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.0.12)\n",
      "Requirement already satisfied: ruamel.yaml==0.17.16 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (0.17.16)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.1.2 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from ruamel.yaml==0.17.16->huggingface-hub<0.1.0,>=0.0.14->datasets) (0.2.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\thiba\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6426dc1",
   "metadata": {},
   "source": [
    "# Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1d0162ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thiba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "390c5446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (C:\\Users\\thiba\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n",
      "Reusing dataset imdb (C:\\Users\\thiba\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    }
   ],
   "source": [
    "# We split the dataset in two categories train and test\n",
    "dataset_train = load_dataset('imdb', split='train')\n",
    "dataset_test = load_dataset('imdb', split='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8c08eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = dataset_train[:]['text'], dataset_train[:]['label'], dataset_test[:]['text'], dataset_test[:]['label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cafda63",
   "metadata": {},
   "source": [
    "Nous modifions maintenant le tableau en dataframe, ce qui permet de plus facilement faire de la visualisation sur le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5905a216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                                 val  label\n",
       " 0  Bromwell High is a cartoon comedy. It ran at t...      1\n",
       " 1  Homelessness (or Houselessness as George Carli...      1\n",
       " 2  Brilliant over-acting by Lesley Ann Warren. Be...      1,\n",
       "                                                  val  label\n",
       " 0  I went and saw this movie last night after bei...      1\n",
       " 1  Actor turned director Bill Paxton follows up h...      1\n",
       " 2  As a recreational golfer with some knowledge o...      1)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(list(zip(x_train, y_train)), columns=['val', 'label'])\n",
    "df_test = pd.DataFrame(list(zip(x_test, y_test)), columns=['val', 'label'])\n",
    "df_train.head(3), df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a15fb1",
   "metadata": {},
   "source": [
    "# Prétraitement\n",
    "\n",
    "Nous appliquons maintenant un simple stemmer en utilisant NLTK PorterStemmer sur chaqu'un des mots d'une review et ceci sur chaque review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "94124e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "x_train_stemmed = df_train['val'].apply(simple_stemmer)\n",
    "x_test_stemmed = df_test['val'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e08a4c",
   "metadata": {},
   "source": [
    "Nous appliquons pour une nouveau tableau un lemmatizer de NLTK sur chaqu'un des mots d'une review et ceci sur chaque review de film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "72f03883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text= ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text\n",
    "x_train_lemmed = df_train['val'].apply(lemm)\n",
    "x_test_lemmed = df_test['val'].apply(lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8019ba5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I went and saw this movie last night after being coaxed to by a few friend of mine. I'll admit that I wa reluctant to see it because from what I knew of Ashton Kutcher he wa only able to do comedy. I wa wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which wa sold out) wa overcome by laughter during the first half of the movie, and were moved to tear during the second half. While exiting the theater I not only saw many woman in tears, but many full grown men a well, trying desperately not to let anyone see them crying. This movie wa great, and I suggest that you go see it before you judge.\""
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exemple entre une review lemmatizer et une non lemmatizer\n",
    "x_test_lemmed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d4fbc672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\""
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3da4e8",
   "metadata": {},
   "source": [
    "Nous modifions maintenant nos tableau de review en TF-IDF(term frequency-inverse document frequency) ceci permet d'avoir une mesure statistique de ce qui est contenue dans une review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "06ff51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf des tableau sans prétraitement\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_train = tf_idf_vect.fit_transform(x_train)\n",
    "tf_idf_test = tf_idf_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7291d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf des tableau stemmmer\n",
    "tf_idf_vect_stemmed = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_train_stemmed = tf_idf_vect_stemmed.fit_transform(x_train_stemmed)\n",
    "tf_idf_test_stemmed = tf_idf_vect_stemmed.transform(x_test_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a11fe935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf des tableau lemmer\n",
    "tf_idf_vect_lemmed = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_train_lemmed = tf_idf_vect_lemmed.fit_transform(x_train_lemmed)\n",
    "tf_idf_test_lemmed = tf_idf_vect_lemmed.transform(x_test_lemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610155b2",
   "metadata": {},
   "source": [
    "# Modele Naive Bayes\n",
    "Pour le naive bayes nous avons choisit MultinomialNB, car il est adapté au contage de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1d2bae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87     12500\n",
      "           1       0.90      0.83      0.86     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(tf_idf_train,y_train)\n",
    "y_pred_test = clf.predict(tf_idf_test)\n",
    "report = classification_report(y_test,y_pred_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d2614bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87     12500\n",
      "           1       0.90      0.83      0.86     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test,y_pred_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b7c248ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87     12500\n",
      "           1       0.90      0.82      0.86     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.86     25000\n",
      "weighted avg       0.87      0.87      0.86     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(tf_idf_train_stemmed,y_train)\n",
    "y_pred_test_stemmed = clf.predict(tf_idf_test_stemmed)\n",
    "report_stemmed = classification_report(y_test,y_pred_test_stemmed)\n",
    "print(report_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "77f3bfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87     12500\n",
      "           1       0.90      0.82      0.86     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(tf_idf_train_lemmed,y_train)\n",
    "y_pred_test_lemmed = clf.predict(tf_idf_test_lemmed)\n",
    "report_lemmed = classification_report(y_test,y_pred_test_lemmed)\n",
    "print(report_lemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9826bf",
   "metadata": {},
   "source": [
    "#### On peut remarquer que les resultats sont vraiment similaires avec ou sans prétraitement ce qui ne parait pas normal, cependant on obtiens de vraiment bon résultats en général"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c626432",
   "metadata": {},
   "source": [
    "# Analyse\n",
    "Maintenant nous allons montrer des résultats dont le Naive bayes s'est trompé, et nous allons essayer de comprendre pourquoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f82b9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cela aurait du être positif mais l'algo a eu négatif\n",
      "My wife is a mental health therapist and we watched it from beginning to end. I am the typical man and can not stand chick flicks, but this movie is unbelievable. If you want to see what it is like for someone who is going through these type of struggles, this is the movie for you. As I watched it I found myself feeling sorry for him and others like him. <br /><br />***Spoiler*** Plus the fact that all the individuals in the movie including the people in the mental institution were the actual people in real life made it that more real.<br /><br />A must see for someone in the mental health profession!\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2000):\n",
    "    if y_test[i] != y_pred_test_lemmed[i]:\n",
    "        if (y_test[i] == 1):\n",
    "            print(\"Cela aurait du être positif mais l'algo a eu négatif\")\n",
    "            print(x_test[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c776d940",
   "metadata": {},
   "source": [
    "De cet example dont l'algorithme bayes naive a eu négatif alors que la review était positive, on peut en déduire c'est a cause de la répétition de mot tel que \"can not stand\" \"feeling sorry\", la review en général n'est pas négative mais elle ne contient que peu de mot positif, c'est une revue assez neutre c'est pour cela que notre algorithme n'a pas détecter de répétition de mot dit \"positif\" et en a donc mal conclue que c'était une revue négative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7af3766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cela aurait du être négatif mais l'algo a eu positif\n",
      "Brass pictures (movies is not a fitting word for them) really are somewhat brassy. Their alluring visual qualities are reminiscent of expensive high class TV commercials. But unfortunately Brass pictures are feature films with the pretense of wanting to entertain viewers for over two hours! In this they fail miserably, their undeniable, but rather soft and flabby than steamy, erotic qualities non withstanding.<br /><br />Senso '45 is a remake of a film by Luchino Visconti with the same title and Alida Valli and Farley Granger in the lead. The original tells a story of senseless love and lust in and around Venice during the Italian wars of independence. Brass moved the action from the 19th into the 20th century, 1945 to be exact, so there are Mussolini murals, men in black shirts, German uniforms or the tattered garb of the partisans. But it is just window dressing, the historic context is completely negligible.<br /><br />Anna Galiena plays the attractive aristocratic woman who falls for the amoral SS guy who always puts on too much lipstick. She is an attractive, versatile, well trained Italian actress and clearly above the material. Her wide range of facial expressions (signalling boredom, loathing, delight, fear, hate ... and ecstasy) are the best reason to watch this picture and worth two stars. She endures this basically trashy stuff with an astonishing amount of dignity. I wish some really good parts come along for her. She really deserves it.\n"
     ]
    }
   ],
   "source": [
    "for i in range(12500,25000):\n",
    "    if y_test[i] != y_pred_test_lemmed[i]:\n",
    "        if (y_test[i] == 0):\n",
    "            print(\"Cela aurait du être négatif mais l'algo a eu positif\")\n",
    "            print(x_test[i])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603123cc",
   "metadata": {},
   "source": [
    "De cet autre example dont l'algorithme bayes naive a eu positif alors que la review était à charactère négatif, même si le commentaire est dans une première partie très négatif avec la présence de mot tel que \"fail\" \"miserably\", l'algorithme a due être trompé due a la présence de mot tel que \"quality\" \"love\" etc... Mais aussi par tout ce paragraphe où l'auteur décrit avec positivité la qualité de l'actrice, l'algorithme a surement donc vu beaucoup de vocabulaire qu'il a pensé positif comparé à un champ léxical négatif."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
